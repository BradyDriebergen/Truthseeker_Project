{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification with Huggingface+BERT fine-tuning\n",
    "\n",
    "- We'll be using the IMDB dataset, which you need to [download](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) and extract, set the `data_base_folder` to the extracted folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "    text = re.sub('\\t', ' ',  text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text\n",
    "\n",
    "def load_data(path):\n",
    "    onlyfiles = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    print('found {} files'.format(len(onlyfiles)))\n",
    "    all_text = []\n",
    "    for f in onlyfiles:\n",
    "        with open('{}/{}'.format(path, f)) as handle:\n",
    "            lines = clean_text(handle.readlines()[0])\n",
    "            all_text.append(lines)\n",
    "        \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_folder = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134198, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/Truth_Seeker_Model_Dataset.csv\")\n",
    "#neg = load_data('{}/train/neg'.format(data_base_folder))\n",
    "#pos = load_data('{}/train/pos'.format(data_base_folder))\n",
    "#train_labels = np.array([[1,0]]*len(neg) + [[0,1]]*len(pos))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111593, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['5_label_majority_answer'].isin(['NO MAJORITY'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement-and-tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134192</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134193</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134194</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134195</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134197</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111593 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      statement-and-tweet\n",
       "0       True Statement: End of eviction moratorium mea...\n",
       "2       True Statement: End of eviction moratorium mea...\n",
       "3       True Statement: End of eviction moratorium mea...\n",
       "4       True Statement: End of eviction moratorium mea...\n",
       "5       True Statement: End of eviction moratorium mea...\n",
       "...                                                   ...\n",
       "134192  False Statement: Joe Bidens great-grandfather ...\n",
       "134193  False Statement: Joe Bidens great-grandfather ...\n",
       "134194  False Statement: Joe Bidens great-grandfather ...\n",
       "134195  False Statement: Joe Bidens great-grandfather ...\n",
       "134197  False Statement: Joe Bidens great-grandfather ...\n",
       "\n",
       "[111593 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame()\n",
    "sentences['statement-and-tweet'] = df['target'].astype(str) + ' Statement: '  +  df['statement'] + '| Tweet: ' +df['tweet']\n",
    "#sentences = df['target'].astype(str) + ' Statement: '  +  df['statement'] + '| Tweet: ' +df['tweet']\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_truthfulness_4way(row):\n",
    "    if row['target'] == True:\n",
    "        if row['5_label_majority_answer'] == 'Agree':\n",
    "            return \"True\"\n",
    "        elif row['5_label_majority_answer'] == 'Disagree':\n",
    "            return \"False\"\n",
    "        elif row['5_label_majority_answer'] == 'Mostly Agree':\n",
    "            return \"Mostly True\"\n",
    "        elif row['5_label_majority_answer'] == 'Mostly Disagree':\n",
    "            return \"Mostly False\"\n",
    "    else:\n",
    "        if row['5_label_majority_answer'] == 'Agree':\n",
    "            return \"False\"\n",
    "        elif row['5_label_majority_answer'] == 'Disagree':\n",
    "            return \"True\"\n",
    "        elif row['5_label_majority_answer'] == 'Mostly Agree':\n",
    "            return \"Mostly False\"\n",
    "        elif row['5_label_majority_answer'] == 'Mostly Disagree':\n",
    "            return \"Mostly True\"\n",
    "\n",
    "def generate_truthfulness_2way(row):\n",
    "    if row['target'] == True:\n",
    "        if row['3_label_majority_answer'] == 'Agree':\n",
    "            return \"True\"\n",
    "        elif row['3_label_majority_answer'] == 'Disagree':\n",
    "            return \"False\"\n",
    "    else:\n",
    "        if row['3_label_majority_answer'] == 'Agree':\n",
    "            return \"False\"\n",
    "        elif row['3_label_majority_answer'] == 'Disagree':\n",
    "            return \"True\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4-way-label</th>\n",
       "      <th>2-way-label</th>\n",
       "      <th>2-way-label-B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mostly True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mostly True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134192</th>\n",
       "      <td>Mostly False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134193</th>\n",
       "      <td>Mostly False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134194</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134195</th>\n",
       "      <td>Mostly False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111593 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4-way-label 2-way-label 2-way-label-B\n",
       "0        Mostly True        True          True\n",
       "2               True        True          True\n",
       "3        Mostly True        True          True\n",
       "4               True        True          True\n",
       "5               True        True          True\n",
       "...              ...         ...           ...\n",
       "134192  Mostly False       False         False\n",
       "134193  Mostly False       False         False\n",
       "134194         False       False         False\n",
       "134195  Mostly False       False         False\n",
       "134197         False       False         False\n",
       "\n",
       "[111593 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['4-way-label'] = df.apply(lambda x: generate_truthfulness_4way(x), axis=1)\n",
    "df2['2-way-label'] = df.apply(lambda x: generate_truthfulness_2way(x), axis=1)\n",
    "df2['2-way-label-B'] = df.apply(lambda x: generate_truthfulness_2way(x), axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248129/4105862823.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df2['2-way-label'] = df2['2-way-label'].replace({'True': 0, 'False': 1})\n",
      "/tmp/ipykernel_248129/4105862823.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df2['2-way-label-B'] = df2['2-way-label-B'].replace({'True': 1, 'False': 0})\n"
     ]
    }
   ],
   "source": [
    "df2['2-way-label'] = df2['2-way-label'].replace({'True': 0, 'False': 1})\n",
    "df2['2-way-label-B'] = df2['2-way-label-B'].replace({'True': 1, 'False': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statemen-and-tweet</th>\n",
       "      <th>labels1</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True Statement: End of eviction moratorium mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134192</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134193</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134194</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134195</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134197</th>\n",
       "      <td>False Statement: Joe Bidens great-grandfather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111593 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       statemen-and-tweet  labels1  labels2\n",
       "0       True Statement: End of eviction moratorium mea...        0        1\n",
       "2       True Statement: End of eviction moratorium mea...        0        1\n",
       "3       True Statement: End of eviction moratorium mea...        0        1\n",
       "4       True Statement: End of eviction moratorium mea...        0        1\n",
       "5       True Statement: End of eviction moratorium mea...        0        1\n",
       "...                                                   ...      ...      ...\n",
       "134192  False Statement: Joe Bidens great-grandfather ...        1        0\n",
       "134193  False Statement: Joe Bidens great-grandfather ...        1        0\n",
       "134194  False Statement: Joe Bidens great-grandfather ...        1        0\n",
       "134195  False Statement: Joe Bidens great-grandfather ...        1        0\n",
       "134197  False Statement: Joe Bidens great-grandfather ...        1        0\n",
       "\n",
       "[111593 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['statemen-and-tweet'] = sentences['statement-and-tweet']\n",
    "dataset['labels1'] = df2['2-way-label']\n",
    "dataset['labels2'] = df2['2-way-label-B']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the DataFrame into 80% train and 20% test\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statemen-and-tweet</th>\n",
       "      <th>labels1</th>\n",
       "      <th>labels2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125030</th>\n",
       "      <td>False Statement: Says President Barack Obama s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>True Statement: The federal American Rescue Pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84384</th>\n",
       "      <td>False Statement: If I dont take the vaccine, I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28919</th>\n",
       "      <td>True Statement: Both the Democratic and Republ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58762</th>\n",
       "      <td>True Statement: \"There are more African Americ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18158</th>\n",
       "      <td>True Statement: \"You know what Amazon paid in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70583</th>\n",
       "      <td>True Statement: Americans spend more than $160...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37418</th>\n",
       "      <td>True Statement: \"Building a wall\" on the U.S.-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25734</th>\n",
       "      <td>True Statement: Says Warren Buffett has public...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110611</th>\n",
       "      <td>False Statement: Early morning election result...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22319 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       statemen-and-tweet  labels1  labels2\n",
       "125030  False Statement: Says President Barack Obama s...        1        0\n",
       "3120    True Statement: The federal American Rescue Pl...        0        1\n",
       "84384   False Statement: If I dont take the vaccine, I...        1        0\n",
       "28919   True Statement: Both the Democratic and Republ...        0        1\n",
       "58762   True Statement: \"There are more African Americ...        0        1\n",
       "...                                                   ...      ...      ...\n",
       "18158   True Statement: \"You know what Amazon paid in ...        0        1\n",
       "70583   True Statement: Americans spend more than $160...        0        1\n",
       "37418   True Statement: \"Building a wall\" on the U.S.-...        0        1\n",
       "25734   True Statement: Says Warren Buffett has public...        0        1\n",
       "110611  False Statement: Early morning election result...        1        0\n",
       "\n",
       "[22319 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>125030</th>\n",
       "      <th>3120</th>\n",
       "      <th>84384</th>\n",
       "      <th>28919</th>\n",
       "      <th>58762</th>\n",
       "      <th>78220</th>\n",
       "      <th>27229</th>\n",
       "      <th>106589</th>\n",
       "      <th>128001</th>\n",
       "      <th>63247</th>\n",
       "      <th>...</th>\n",
       "      <th>115814</th>\n",
       "      <th>120898</th>\n",
       "      <th>114441</th>\n",
       "      <th>80090</th>\n",
       "      <th>12826</th>\n",
       "      <th>18158</th>\n",
       "      <th>70583</th>\n",
       "      <th>37418</th>\n",
       "      <th>25734</th>\n",
       "      <th>110611</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         125030  3120    84384   28919   58762   78220   27229   106589  \\\n",
       "labels1       1       0       1       0       0       1       0       1   \n",
       "labels2       0       1       0       1       1       0       1       0   \n",
       "\n",
       "         128001  63247   ...  115814  120898  114441  80090   12826   18158   \\\n",
       "labels1       1       0  ...       1       1       1       1       0       0   \n",
       "labels2       0       1  ...       0       0       0       0       1       1   \n",
       "\n",
       "         70583   37418   25734   110611  \n",
       "labels1       0       0       0       1  \n",
       "labels2       1       1       1       0  \n",
       "\n",
       "[2 rows x 22319 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(test_dataset[['labels1','labels2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22319,), (22319, 2))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array(test_dataset['statemen-and-tweet'])\n",
    "test_labels = np.array(test_dataset[['labels1','labels2']])\n",
    "test_data.shape, test_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this for for when it was a single vector\n",
    "#test_labels = np.transpose(np.transpose(test_labels[:, np.newaxis]))\n",
    "#test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False Statement: Says President Barack Obama spied on my campaign, and got caught!| Tweet: Trump: \"Well, look, the Obama campaign spied on our campaign, &amp; they\\'ve been caught, all right?\" He added, \"It\\'s probably treason. It\\'s a horrible thing they did... They used the intelligence agencies of our country to spy on my campaign, &amp; they have been caught.\" \\nALL LIES!',\n",
       "       'True Statement: The federal American Rescue Plan will purchase more food from farmers for distribution.\"| Tweet: You want to see real systemic racism? Look no further than Joe Bidens American rescue plan. The plan pays up to 120% of Black, Hispanic, Asian or Native American farmers\\' outstanding debt. But if youre a white farmer, you get no benefits.',\n",
       "       'False Statement: If I dont take the vaccine, Im at risk for covid. If I do take the vaccine, Im still at risk for covid PLUS Im at risk for permanent vaccine side effects. Therefore Im reducing my risk by not taking the vaccine. Thats the real science.| Tweet: @YardleyShooting The real science:\\n\\nIf I dont take the vaccine,\\nIm at risk from Covid.\\n\\nIf I do take the vaccine,\\nIm still at risk from Covid.\\nNevermind the side effects from having the jab.\\n\\nTherefore Im reducing my risks by not taking the vaccine.....',\n",
       "       ...,\n",
       "       'True Statement: \"Building a wall\" on the U.S.-Mexico border \"will take literally years.\"| Tweet: @EdKrassen ...Houses come w/ locks; theyre not a $25 B add-on. The wall is more like building an alligator-stocked moat (that will take 10 years to build) to protect your house from flying rutabagas that you think are there now.',\n",
       "       'True Statement: Says Warren Buffett has publicly said his secretary \"should not be paying a higher tax rate\" than him.| Tweet: @POTUS Warren buffet said said he pays a lower tax rate than his secretary\\n\\nThis was in 2013...',\n",
       "       'False Statement: Early morning election results from Michigan and Wisconsin show voter fraud.| Tweet: Looks like Michigan and Wisconsin are completely being exposed today. Voter Impropriety and downright fraud.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89274,), (89274,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.array(train_dataset['statemen-and-tweet'])\n",
    "train_labels = np.array(train_dataset[['labels1','labels2']])\n",
    "train_data.shape, train_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = np.transpose(np.transpose(train_labels[:, np.newaxis]))\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['True Statement: \"The Walton family of Walmart ... This one family owns more wealth than the bottom 40 percent of the American people.\"| Tweet: @glennbeck People are sick of having $1k+ a month taken out of paychecks for health care. When they\\'re told the Walton family has more wealth than 50% of Americans combined, the message resonates. You can call them naive, etc but that\\'s what Dems said last time about Trump voters too',\n",
       "       'True Statement: \"Todays marijuana is 300 percent to 800 percent more potent than the pot of yesteryear.\"| Tweet: Always Stay away from using some Gateway drugs such as Nicotine(Socially acceptable but dangerous),Alcohol and Marijuana becz it opens the door to harder and more potent drugs.',\n",
       "       'False Statement: The southern U.S. border is now open to anyone from anywhere in the world who wishes to enter our country.| Tweet: @Robert58742051 @brguest20 Selfish? You mean like pulling troops out of Afghanistan when trouble is starting and then going on vacation? Or how about insisting everyone get vaccinated and wear masks and yet open the southern border 2 allow thousands of unvaccinated unmasked illegal immigrants into the U.S?',\n",
       "       ...,\n",
       "       'True Statement: Ronald Reagan \"raised taxes in 1982, 1984, 1985, 1986 and 1987.\"| Tweet: @realDonaldTrump And like Ronald Reagan, this will be immediately revoked and taxes raised 11 times and after youre impeached will be reversed for the good of us middle class and poor people. Especially since its being funded by OUR Medicare and social security',\n",
       "       'False Statement: \"Black Lives Matter is a terrorist organization.\"| Tweet: Black Lives Matter is a hate group and should be labeled as a domestic terrorist organization.',\n",
       "       'True Statement: \"Triggering leftists, Trump\\'s reelection campaign is selling plastic straws.\"| Tweet: @JYSexton Keep grasping at those straws. At this point, youre just helping with Trumps reelection effort.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 12500 files\n",
      "found 12500 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000,), (25000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_neg = load_data('{}/test/neg'.format(data_base_folder))\n",
    "#test_pos = load_data('{}/test/pos'.format(data_base_folder))\n",
    "#test_data = np.array(test_neg+test_pos)\n",
    "#test_labels = np.array([[1,0]]*len(test_neg) + [[0,1]]*len(test_pos))\n",
    "#test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Datasets\n",
    "\n",
    "- takes in inputs and outputs/labels\n",
    "- interfaces with tokenizer\n",
    "- handles batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Class\n",
    "\n",
    "- first \"layer\" is a pre-trained BERT model\n",
    "- you can add whatever layers you want after that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, NUM_OUT):\n",
    "        super(BERTClass, self).__init__()\n",
    "                   \n",
    "        self.l1 = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#         self.pre_classifier = torch.nn.Linear(768, 256)\n",
    "        self.classifier = torch.nn.Linear(768, NUM_OUT)\n",
    "#         self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "#         pooler = self.pre_classifier(pooler)\n",
    "#         pooler = torch.nn.Tanh()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Functions\n",
    "\n",
    "Loss\n",
    "\n",
    "- This task is binary, so it uses binary crossentropy loss\n",
    "- Tasks with more labels will use categorical crossentropy\n",
    "- Tasks that don't have labels, but rather have distributions should use KL divergence\n",
    "- Tasks that don't have distributions should use something like RMSE loss\n",
    "\n",
    "Train\n",
    "\n",
    "- Steps through the data batch by batch\n",
    "- grabs ids, masks, and token_type_ids which are required inputs for BERT\n",
    "- inputs are passed through the model, compared to targets, computes loss function, backprops\n",
    "\n",
    "Validation\n",
    "\n",
    "- Takes a model, passes inputs\n",
    "- Need to use the targets from here because they are potentially shuffled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCELoss()(outputs, targets)\n",
    "\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "    \n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = torch.sigmoid(outputs).cpu().detach()\n",
    "            fin_outputs.extend(outputs)\n",
    "            fin_targets.extend(targets)\n",
    "    return torch.stack(fin_outputs), torch.stack(fin_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tokenizer\n",
    "\n",
    "- Converts a raw string to the ids, masks, and token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Statement: Says John F. Kennedy said, \"If a Supreme Court Justice died one day before the election, it would be more Constitutional to indefinitely postpone the election than postpone the confirmation a single day.\"| Tweet: Wow...Justice Kennedy, who could be the deciding vote in the gay marriage Supreme Court vote said to remember the children...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/demo/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 6270, 4861, 1024, 2758, 2198, 1042, 1012, 5817, 2056, 1010, 1000, 2065, 1037, 4259, 2457, 3425, 2351, 2028, 2154, 2077, 1996, 2602, 1010, 2009, 2052, 2022, 2062, 6543, 2000, 20733, 2695, 29513, 1996, 2602, 2084, 2695, 29513, 1996, 13964, 1037, 2309, 2154, 1012, 1000, 1064, 1056, 28394, 2102, 1024, 10166, 1012, 1012, 1012, 3425, 5817, 1010, 2040, 2071, 2022, 1996, 10561, 3789, 1999, 1996, 5637, 3510, 4259, 2457, 3789, 2056, 2000, 3342, 1996, 2336, 1012, 1012, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# what does the tokenizer do?\n",
    "print(train_data[5])\n",
    "\n",
    "tokenizer.encode_plus(\n",
    "            train_data[5],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup\n",
    "\n",
    "- hyperparameters\n",
    "- setup dataset\n",
    "- setup parameters\n",
    "- setup dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 410\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "NUM_OUT = 2 # binary task\n",
    "LEARNING_RATE = 2e-05\n",
    "\n",
    "training_data = MultiLabelDataset(train_data, torch.from_numpy(train_labels), tokenizer, MAX_LEN)\n",
    "test_data = MultiLabelDataset(test_data, torch.from_numpy(test_labels), tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train,  Evaluate\n",
    "\n",
    "- model.to -> send to GPU, if available (anything computed should be put onto the GPU)\n",
    "- setup optimizer - could use Stochastic Gradient Descent, but ADAM tends to work better\n",
    "- for each epoch, train, show the loss, evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248129/1309693225.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(training_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e021bd53443e4931955ba16d1c15b4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/demo/bert/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_248129/1170955052.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(self.targets[index], dtype=torch.float)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params \u001b[38;5;241m=\u001b[39m  model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m      9\u001b[0m     guess, targs \u001b[38;5;241m=\u001b[39m validation(model, testing_loader)\n",
      "Cell \u001b[0;32mIn[44], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, training_loader, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(ids, mask, token_type_ids)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(outputs, targets):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/bert/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/bert/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/demo/bert/lib/python3.12/site-packages/torch/nn/modules/loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/demo/bert/lib/python3.12/site-packages/torch/nn/functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3548\u001b[0m     )\n\u001b[1;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "model = BERTClass(NUM_OUT)\n",
    "model.to(device)    \n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, training_loader, optimizer)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')  \n",
    "    guess, targs = validation(model, testing_loader)\n",
    "    guesses = torch.max(guess, dim=1)\n",
    "    targets = torch.max(targs, dim=1)\n",
    "    print('arracy on test set {}'.format(accuracy_score(guesses.indices, targets.indices)))\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')  \n",
    "    guess, targs = validation(model, testing_loader)\n",
    "    guesses = torch.max(guess, dim=1)\n",
    "    targets = torch.max(targs, dim=1)\n",
    "    print('arracy on test set {}'.format(accuracy_score(guesses.indices, targets.indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311]),\n",
       "indices=tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
